{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45d3686-b767-4c84-8741-e276ae2d0540",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d7b83-aae6-4754-a848-a1064edd8457",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Llama 2 and BERT model used for example text\n",
    "2. Models used for data that is in a SAS Viya in-memory table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bde491-2741-4fe4-81c3-eb51f18b4a69",
   "metadata": {},
   "source": [
    "## 1. Llama 2 and BERT for example text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eea460-bb91-491c-8f84-1f7947432a19",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daeeede-5a2b-49fc-885a-973ff0b56728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.36.0-py3-none-any.whl.metadata (126 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.36.0-py3-none-any.whl (8.2 MB)\n",
      "Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "Using cached regex-2023.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "Using cached safetensors-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached tokenizers-0.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: safetensors, regex, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.13.1 huggingface-hub-0.19.4 regex-2023.10.3 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.36.0\n",
      "Collecting torch\n",
      "  Using cached torch-2.1.1-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.1.1-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.1 triton-2.1.0\n",
      "Collecting datasets\n",
      "  Using cached datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (13.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.4.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.18.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "Using cached aiohttp-3.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached frozenlist-1.4.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (250 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, multiprocess, multidict, frozenlist, yarl, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 datasets-2.15.0 frozenlist-1.4.0 multidict-6.0.4 multiprocess-0.70.15 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.1)\n",
      "Collecting llama-index==0.9.12\n",
      "  Using cached llama_index-0.9.12-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index==0.9.12) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (3.9.1)\n",
      "Collecting aiostream<0.6.0,>=0.5.2 (from llama-index==0.9.12)\n",
      "  Using cached aiostream-0.5.2-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (4.12.2)\n",
      "Collecting dataclasses-json (from llama-index==0.9.12)\n",
      "  Using cached dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index==0.9.12)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (2023.9.2)\n",
      "Collecting httpx (from llama-index==0.9.12)\n",
      "  Using cached httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (1.5.8)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index==0.9.12)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (1.24.4)\n",
      "Collecting openai>=1.1.0 (from llama-index==0.9.12)\n",
      "  Downloading openai-1.3.9-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index==0.9.12)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index==0.9.12)\n",
      "  Using cached tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from llama-index==0.9.12) (4.8.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index==0.9.12)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.12) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.12) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.12) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.12) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.12) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index==0.9.12) (2.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index==0.9.12) (1.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.12) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.12) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.12) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.12) (4.66.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.1.0->llama-index==0.9.12) (4.0.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index==0.9.12)\n",
      "  Using cached distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai>=1.1.0->llama-index==0.9.12)\n",
      "  Using cached pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai>=1.1.0->llama-index==0.9.12) (1.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx->llama-index==0.9.12) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx->llama-index==0.9.12)\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.11/site-packages (from httpx->llama-index==0.9.12) (3.4)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index==0.9.12)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31.0->llama-index==0.9.12) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31.0->llama-index==0.9.12) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index==0.9.12) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index==0.9.12)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index==0.9.12)\n",
      "  Using cached marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->llama-index==0.9.12) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->llama-index==0.9.12) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->llama-index==0.9.12) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index==0.9.12) (23.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index==0.9.12)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index==0.9.12)\n",
      "  Using cached pydantic_core-2.14.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index==0.9.12) (1.16.0)\n",
      "Using cached llama_index-0.9.12-py3-none-any.whl (927 kB)\n",
      "Using cached aiostream-0.5.2-py3-none-any.whl (39 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading openai-1.3.9-py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "Using cached pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "Using cached pydantic_core-2.14.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, nltk, mypy-extensions, marshmallow, h11, distro, deprecated, annotated-types, aiostream, typing-inspect, tiktoken, pydantic, httpcore, httpx, dataclasses-json, openai, llama-index\n",
      "Successfully installed aiostream-0.5.2 annotated-types-0.6.0 dataclasses-json-0.6.3 deprecated-1.2.14 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 llama-index-0.9.12 marshmallow-3.20.1 mypy-extensions-1.0.0 nltk-3.8.1 openai-1.3.9 pydantic-2.5.2 pydantic-core-2.14.5 tenacity-8.2.3 tiktoken-0.5.2 typing-inspect-0.9.0\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2023.7.22)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.1.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.25.0\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-3.17.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Using cached pypdf-3.17.2-py3-none-any.whl (277 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-3.17.2\n"
     ]
    }
   ],
   "source": [
    "#Needed for BERT NER\n",
    "!pip install transformers\n",
    "!pip install torch #torchvision torchaudio\n",
    "!pip install datasets\n",
    "!pip install tqdm\n",
    "\n",
    "#Swat is needed if you want to score data from SAS Viya in-memory tables\n",
    "#!pip install swat\n",
    "\n",
    "#Needed for Llama2\n",
    "#https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
    "#https://gpt-index.readthedocs.io/en/latest/getting_started/reading.html\n",
    "!pip install llama-index==0.9.12\n",
    "!pip install huggingface_hub\n",
    "!pip install accelerate\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69768c5b-43e0-407a-98b6-7f96811e03cf",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36e1a896-834e-44b7-8b19-a95312a28461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 07:36:40.614060: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 07:36:40.617667: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 07:36:40.658014: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 07:36:40.658059: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 07:36:40.658085: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 07:36:40.666688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 07:36:41.675390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.11/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/opt/conda/lib/python3.11/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/opt/conda/lib/python3.11/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "#For SAS Viya connection\n",
    "import swat\n",
    "\n",
    "#For BERT\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#For Llama 2\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "from llama_index.chat_engine import SimpleChatEngine\n",
    "\n",
    "import accelerate\n",
    "from huggingface_hub.hf_api import HfFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f816eed-8165-4311-81a0-ac457445b61c",
   "metadata": {},
   "source": [
    "## Define the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723f714a-21d1-4824-932a-255ba85f6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find a model fine tuned for NER task.\n",
    "#e.g. -> https://huggingface.co/iguanodon-ai/bert-base-finnish-uncased-ner \n",
    "\n",
    "#https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelfortokenclassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"iguanodon-ai/bert-base-finnish-uncased-ner\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"iguanodon-ai/bert-base-finnish-uncased-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b187083f-292f-499a-a93e-775e5884e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02cd73-b20f-4f0a-ae8e-03e2f02972be",
   "metadata": {},
   "source": [
    "## Inference using the BERT model and only one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ad715a-b206-4901-b5f0-a9e980c6f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_fi = \"Nimeni on Antti. Asun Helsingissä, Suomen pääkaupungissa.\"\n",
    "#example_eng = \"My name is Antti. I live in Helsinki, Finland's capital.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262a3f7a-ca78-49ab-954e-71e710ce2956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.99863523, 'index': 3, 'word': 'antti', 'start': 10, 'end': 15}, {'entity': 'B-LOC', 'score': 0.99538004, 'index': 6, 'word': 'helsingissa', 'start': 22, 'end': 33}, {'entity': 'B-LOC', 'score': 0.9984358, 'index': 8, 'word': 'suomen', 'start': 35, 'end': 41}]\n"
     ]
    }
   ],
   "source": [
    "#https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "ner_results = pipeline(example_fi)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce981fc-a0fc-4b25-9979-376c96708808",
   "metadata": {},
   "source": [
    "## Define Llama 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b4e480-716e-44c7-b918-e9b5d8f102ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#System prompt guides the model\n",
    "SYSTEM_PROMPT = \"\"\"You are an answer bot that answers questions based on the given input. \n",
    "Here are some rules you always follow:\n",
    "- Generate human readable output, avoid creating output with gibberish text.\n",
    "- Generate only the requested output, don't include any other language before or after the requested output.\n",
    "- Answer to the point and keep it short.\n",
    "- Do not guess. \n",
    "\"\"\"\n",
    "\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47813fbe-b307-469a-a2e2-a39f43b9621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save your huggingface token to use the Llama2 model\n",
    "#It is required to apply to access the model -> https://huggingface.co/meta-llama/Llama-2-7b-chat-hf\n",
    "HfFolder.save_token(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7540167-8200-4159-a0aa-2656bcb35a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b4bfa0410242ab864ec716b0331d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Model parameters\n",
    "model_2 = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=1000,\n",
    "    generate_kwargs={#\"temperature\": 0.3, \n",
    "        \"do_sample\": False},\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    device_map=\"auto\",\n",
    "    #stopping_ids=[50278, 50279, 50277, 1, 0],\n",
    "    tokenizer_kwargs={\"max_length\": 4096},\n",
    "    # uncomment this if using CUDA to reduce memory usage\n",
    "    #model_kwargs={\"torch_dtype\": torch.float16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a9609e-1546-451a-9135-cb217824bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03f843961e74afaa5984edef6e1ceab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8083dd7e38436badb61c99a65c89b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60beed6b817b44adb281b7183319099a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174ab7d7659a4044a53713f2471b71d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa6776dc1534d259626ddfca8257826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed7fa649a1649c890fbffcdc09710b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Select embeddings to use\n",
    "#https://huggingface.co/BAAI/bge-small-en-v1.5\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df74c252-bf52-4b25-87ee-dbecdaf01a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "#Set service context\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    chunk_size=1024,\n",
    "    llm=model_2,\n",
    "    embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664ba007-9186-47fe-8e8d-df6eb274d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define chat engine using the set service context\n",
    "chat_engine = SimpleChatEngine.from_defaults(service_context=service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c05137-79ca-4597-9f93-17a593cccd28",
   "metadata": {},
   "source": [
    "## Inference using the Llama 2 model and only one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10472219-35d9-4849-ba2b-64734975c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a query for the model\n",
    "#In this case we use the LLM for entity extraction, but it can be used for any queries\n",
    "query = \"Extract the names of people and locations in the following sentence and provide their start and end positions: 'Nimeni on Antti. Asun Helsingissä, Suomen pääkaupungissa.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35b40ee0-ddaa-4d99-99e2-40385cf3af07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sure! Here are the names of people and locations in the sentence you provided, along with their start and end positions:\\n\\nPeople:\\n\\n1. Nimeni (Nimi) - Start position: 0, End position: 5\\n2. Antti - Start position: 5, End position: 9\\n\\nLocations:\\n\\n1. Helsingissä (Helsinki) - Start position: 9, End position: 14\\n2. Suomen pääkaupungissa (the capital of Finland) - Start position: 14, End position: 24\\n\\nI hope this helps! Let me know if you have any other questions.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Provide the query to the model and get a response\n",
    "response = chat_engine.chat(query).response\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355c63c-c6fd-49ed-a54d-43514749fc32",
   "metadata": {},
   "source": [
    "## 2. Inference on SAS Viya in-memory tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62a2ed-758e-47db-aa21-950173d72452",
   "metadata": {},
   "source": [
    "Next step is to perform inference on a table of records. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1580d12c-57c8-42d4-9a97-54288f02e358",
   "metadata": {},
   "source": [
    "## Create connection to the Viya server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f3a8d2-dff8-4b09-974c-dde0bcfddec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Grid node action status report: 1 nodes, 8 total actions executed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; About</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>{'CAS': 'Cloud Analytic Services', 'Version': '4.00', 'VersionLong': 'V.04.00M0P11132023', 'Viya Release': '20231211.1702320838753', 'Viya Version': 'Stable 2023.11', 'Copyright': 'Copyright © 2014-2023 SAS Institute Inc. All Rights Reserved.', 'ServerTime': '2023-12-13T07:54:39Z', 'System': {'Hostname': 'controller.sas-cas-server-default.cauki.svc.cluster.local', 'OS Name': 'Linux', 'OS Family': 'LIN X64', 'OS Release': '5.15.0-1042-azure', 'OS Version': '#49-Ubuntu SMP Tue Jul 11 17:28:46 UTC 2023', 'Model Number': 'x86_64', 'Linux Distribution': 'Red Hat Enterprise Linux release 8.8 (Ootpa)'}, 'license': {'site': 'VIYADSDEXT', 'siteNum': 70180938, 'expires': '09Feb2024:00:00:00', 'gracePeriod': 45, 'warningPeriod': 45}, 'CASHostAccountRequired': 'OPTIONAL', 'Transferred': 'NO', 'CASCacheLocation': 'CAS Disk Cache'}</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; server</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Server Status</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Node Count\">nodes</th>\n",
       "      <th title=\"Total Actions\">actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; nodestatus</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Node Status</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Node Name\">name</th>\n",
       "      <th title=\"Role\">role</th>\n",
       "      <th title=\"Uptime (Sec)\">uptime</th>\n",
       "      <th title=\"Running\">running</th>\n",
       "      <th title=\"Stalled\">stalled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>controller.sas-cas-server-default.cauki.svc.cl...</td>\n",
       "      <td>controller</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000662s</span> &#183; <span class=\"cas-user\">user 0.00062s</span> &#183; <span class=\"cas-memory\">mem 0.308MB</span></small></p>"
      ],
      "text/plain": [
       "[About]\n",
       "\n",
       " {'CAS': 'Cloud Analytic Services',\n",
       "  'Version': '4.00',\n",
       "  'VersionLong': 'V.04.00M0P11132023',\n",
       "  'Viya Release': '20231211.1702320838753',\n",
       "  'Viya Version': 'Stable 2023.11',\n",
       "  'Copyright': 'Copyright © 2014-2023 SAS Institute Inc. All Rights Reserved.',\n",
       "  'ServerTime': '2023-12-13T07:54:39Z',\n",
       "  'System': {'Hostname': 'controller.sas-cas-server-default.cauki.svc.cluster.local',\n",
       "   'OS Name': 'Linux',\n",
       "   'OS Family': 'LIN X64',\n",
       "   'OS Release': '5.15.0-1042-azure',\n",
       "   'OS Version': '#49-Ubuntu SMP Tue Jul 11 17:28:46 UTC 2023',\n",
       "   'Model Number': 'x86_64',\n",
       "   'Linux Distribution': 'Red Hat Enterprise Linux release 8.8 (Ootpa)'},\n",
       "  'license': {'site': 'VIYADSDEXT',\n",
       "   'siteNum': 70180938,\n",
       "   'expires': '09Feb2024:00:00:00',\n",
       "   'gracePeriod': 45,\n",
       "   'warningPeriod': 45},\n",
       "  'CASHostAccountRequired': 'OPTIONAL',\n",
       "  'Transferred': 'NO',\n",
       "  'CASCacheLocation': 'CAS Disk Cache'}\n",
       "\n",
       "[server]\n",
       "\n",
       " Server Status\n",
       " \n",
       "    nodes  actions\n",
       " 0      1        8\n",
       "\n",
       "[nodestatus]\n",
       "\n",
       " Node Status\n",
       " \n",
       "                                                 name        role  uptime  running  stalled\n",
       " 0  controller.sas-cas-server-default.cauki.svc.cl...  controller   0.276        0        0\n",
       "\n",
       "+ Elapsed: 0.000662s, user: 0.00062s, mem: 0.308mb"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn= swat.CAS(viyaurl, port, username, password)\n",
    "conn.serverstatus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65697a-e029-4cfe-a3b9-8e940626f293",
   "metadata": {},
   "source": [
    "## Check in-memory tables in casuser library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40052f4c-2ae8-49d7-8d4c-36680b222a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; TableInfo</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"Name\">Name</th>\n",
       "      <th title=\"Rows\">Rows</th>\n",
       "      <th title=\"Columns\">Columns</th>\n",
       "      <th title=\"Indexed Columns\">IndexedColumns</th>\n",
       "      <th title=\"Encoding\">Encoding</th>\n",
       "      <th title=\"Created\">CreateTimeFormatted</th>\n",
       "      <th title=\"Last Modified\">ModTimeFormatted</th>\n",
       "      <th title=\"Last Accessed\">AccessTimeFormatted</th>\n",
       "      <th title=\"Character Set\">JavaCharSet</th>\n",
       "      <th title=\"CreateTime\">CreateTime</th>\n",
       "      <th title=\"View\">View</th>\n",
       "      <th title=\"MultiPart\">MultiPart</th>\n",
       "      <th title=\"Loaded Source\">SourceName</th>\n",
       "      <th title=\"Source Caslib\">SourceCaslib</th>\n",
       "      <th title=\"Compressed\">Compressed</th>\n",
       "      <th title=\"Table Creator\">Creator</th>\n",
       "      <th title=\"Last Table Modifier\">Modifier</th>\n",
       "      <th title=\"Source Modified\">SourceModTimeFormatted</th>\n",
       "      <th title=\"SourceModTime\">SourceModTime</th>\n",
       "      <th title=\"Table Redistribute Up Policy\">TableRedistUpPolicy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>TEST_ANONYMIZATION</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>2023-12-13T06:48:37+00:00</td>\n",
       "      <td>2023-12-13T06:48:37+00:00</td>\n",
       "      <td>2023-12-13T07:19:14+00:00</td>\n",
       "      <td>UTF8</td>\n",
       "      <td>2.018069e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_ANONYMIZATION.sashdat</td>\n",
       "      <td>CASUSER(ssfahe)</td>\n",
       "      <td>0</td>\n",
       "      <td>ssfahe</td>\n",
       "      <td></td>\n",
       "      <td>2023-11-14T09:10:58+00:00</td>\n",
       "      <td>2.015572e+09</td>\n",
       "      <td>Not Specified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>TEST_ANONYMIZATION_LLM</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>utf-8</td>\n",
       "      <td>2023-12-13T06:48:47+00:00</td>\n",
       "      <td>2023-12-13T06:48:47+00:00</td>\n",
       "      <td>2023-12-13T06:48:53+00:00</td>\n",
       "      <td>UTF8</td>\n",
       "      <td>2.018069e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TEST_ANONYMIZATION_LLM.sashdat</td>\n",
       "      <td>CASUSER(ssfahe)</td>\n",
       "      <td>0</td>\n",
       "      <td>ssfahe</td>\n",
       "      <td></td>\n",
       "      <td>2023-12-11T08:05:37+00:00</td>\n",
       "      <td>2.017901e+09</td>\n",
       "      <td>Not Specified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.0015s</span> &#183; <span class=\"cas-user\">user 0.000906s</span> &#183; <span class=\"cas-sys\">sys 0.000295s</span> &#183; <span class=\"cas-memory\">mem 0.73MB</span></small></p>"
      ],
      "text/plain": [
       "[TableInfo]\n",
       "\n",
       "                      Name  Rows  Columns  IndexedColumns Encoding        CreateTimeFormatted           ModTimeFormatted        AccessTimeFormatted JavaCharSet    CreateTime       ModTime    AccessTime  Global  Repeated  View  MultiPart                      SourceName     SourceCaslib  Compressed Creator Modifier     SourceModTimeFormatted  SourceModTime TableRedistUpPolicy\n",
       " 0      TEST_ANONYMIZATION    17        2               0    utf-8  2023-12-13T06:48:37+00:00  2023-12-13T06:48:37+00:00  2023-12-13T07:19:14+00:00        UTF8  2.018069e+09  2.018069e+09  2.018071e+09       1         0     0          0      TEST_ANONYMIZATION.sashdat  CASUSER(ssfahe)           0  ssfahe           2023-11-14T09:10:58+00:00   2.015572e+09       Not Specified\n",
       " 1  TEST_ANONYMIZATION_LLM    18        2               0    utf-8  2023-12-13T06:48:47+00:00  2023-12-13T06:48:47+00:00  2023-12-13T06:48:53+00:00        UTF8  2.018069e+09  2.018069e+09  2.018069e+09       1         0     0          0  TEST_ANONYMIZATION_LLM.sashdat  CASUSER(ssfahe)           0  ssfahe           2023-12-11T08:05:37+00:00   2.017901e+09       Not Specified\n",
       "\n",
       "+ Elapsed: 0.0015s, user: 0.000906s, sys: 0.000295s, mem: 0.73mb"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.tableinfo(caslib='casuser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1db5b-459d-42d3-9803-f9e6546c58f7",
   "metadata": {},
   "source": [
    "## Create dataframe out of in-memory table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1aa75b7-0316-4a98-b297-4e41a62f083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table TEST_ANONYMIZATION</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"ID\">ID</th>\n",
       "      <th title=\"Text\">Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Osoitteeni on Helsingintie 10 A 15. Nimeni on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asun Helsingissä. Nimeni on Asko Arvola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Puhelinnumeroni on 040 123 899 3454.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mun nimi on Juhani Numminen ja asun Espoossa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mun nimi on Juhani Teppo Numminen.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Selected Rows from Table TEST_ANONYMIZATION\n",
       "\n",
       "    ID                                               Text\n",
       "0  1.0  Osoitteeni on Helsingintie 10 A 15. Nimeni on ...\n",
       "1  2.0           Asun Helsingissä. Nimeni on Asko Arvola.\n",
       "2  3.0               Puhelinnumeroni on 040 123 899 3454.\n",
       "3  4.0      Mun nimi on Juhani Numminen ja asun Espoossa.\n",
       "4  5.0                 Mun nimi on Juhani Teppo Numminen."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl = conn.CASTable('TEST_ANONYMIZATION', caslib='CASUSER')\n",
    "tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7bc58a1-264e-420d-94d0-b61758d1ed9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tbl refers to CAS in-memory table\n",
    "#Next it is converted into a dataframe\n",
    "df = tbl.to_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abb07760-2a7c-475f-9f85-70b7007750ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table TEST_ANONYMIZATION</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"ID\">ID</th>\n",
       "      <th title=\"Text\">Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Osoitteeni on Helsingintie 10 A 15. Nimeni on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asun Helsingissä. Nimeni on Asko Arvola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Puhelinnumeroni on 040 123 899 3454.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mun nimi on Juhani Numminen ja asun Espoossa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mun nimi on Juhani Teppo Numminen.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Selected Rows from Table TEST_ANONYMIZATION\n",
       "\n",
       "    ID                                               Text\n",
       "0  1.0  Osoitteeni on Helsingintie 10 A 15. Nimeni on ...\n",
       "1  2.0           Asun Helsingissä. Nimeni on Asko Arvola.\n",
       "2  3.0               Puhelinnumeroni on 040 123 899 3454.\n",
       "3  4.0      Mun nimi on Juhani Numminen ja asun Espoossa.\n",
       "4  5.0                 Mun nimi on Juhani Teppo Numminen."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validate by getting the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "380b89ca-94bb-476f-8b73-651af9f3634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/docs/datasets/loading\n",
    "#See Pandas Dataframe section\n",
    "#Convert dataframe into huggingface dataset\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b84ffb08-2fe4-4218-9d43-c7b9b5f1d05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ID', 'Text', '__index_level_0__'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check result\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0609e-7fbb-4df0-bef8-13bea6e33809",
   "metadata": {},
   "source": [
    "## Run dataset through the BERT NER pipeline and check recognized entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2b43a36-c1e8-4d28-9960-bc658cb4579d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f625b2df14674778bdda91bcea20446e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                    Result\n",
      "0  [{'entity': 'B-LOC', 'score': 0.96721745, 'index': 4, 'word': 'helsingin', 'start': 14, 'end': 23}, {'entity': 'B-LOC', 'score': 0.47763294, 'index': 5, 'word': '##tie', 'start': 23, 'end': 26}, {...\n",
      "1  [{'entity': 'B-LOC', 'score': 0.8599525, 'index': 2, 'word': 'helsingissa', 'start': 5, 'end': 16}, {'entity': 'B-PER', 'score': 0.99738044, 'index': 6, 'word': 'asko', 'start': 28, 'end': 32}, {'...\n",
      "2                                                                                                                                                                                                       []\n",
      "3  [{'entity': 'B-PER', 'score': 0.99826485, 'index': 4, 'word': 'juhani', 'start': 12, 'end': 18}, {'entity': 'I-PER', 'score': 0.9983398, 'index': 5, 'word': 'numminen', 'start': 19, 'end': 27}, {'...\n",
      "4  [{'entity': 'B-PER', 'score': 0.9960212, 'index': 4, 'word': 'juhani', 'start': 12, 'end': 18}, {'entity': 'I-PER', 'score': 0.99781346, 'index': 5, 'word': 'teppo', 'start': 19, 'end': 24}, {'ent...\n"
     ]
    }
   ],
   "source": [
    "#%%timeit -r 1\n",
    "#Run time is milliseconds\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "#Define empty frame\n",
    "outputtbl = []\n",
    "\n",
    "#Define for-loop\n",
    "#Text variable in the dataset object is fed into the BERT NER model pipeline defined earlier\n",
    "for out in tqdm(pipeline(KeyDataset(dataset, \"Text\"))):\n",
    "    result = {\n",
    "        'Result': out\n",
    "    }\n",
    "    outputtbl.append(result)\n",
    "\n",
    "#Results are available in the dataframe\n",
    "outdf = pd.DataFrame(outputtbl)\n",
    "print(outdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d53fc753-6bd8-4043-8921-d7cf49aa3bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66103068e24404da3c6ec987c8eb103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-LOC', 'score': 0.96721745, 'index': 4, 'word': 'helsingin', 'start': 14, 'end': 23}, {'entity': 'B-LOC', 'score': 0.47763294, 'index': 5, 'word': '##tie', 'start': 23, 'end': 26}, {'entity': 'I-LOC', 'score': 0.633142, 'index': 6, 'word': '10', 'start': 27, 'end': 29}, {'entity': 'B-PER', 'score': 0.9971386, 'index': 12, 'word': 'esko', 'start': 46, 'end': 50}, {'entity': 'I-PER', 'score': 0.98933697, 'index': 13, 'word': 'esimerkki', 'start': 51, 'end': 60}]\n",
      "[{'entity': 'B-LOC', 'score': 0.8599525, 'index': 2, 'word': 'helsingissa', 'start': 5, 'end': 16}, {'entity': 'B-PER', 'score': 0.99738044, 'index': 6, 'word': 'asko', 'start': 28, 'end': 32}, {'entity': 'I-PER', 'score': 0.99898237, 'index': 7, 'word': 'arvo', 'start': 33, 'end': 37}, {'entity': 'I-PER', 'score': 0.9988759, 'index': 8, 'word': '##la', 'start': 37, 'end': 39}]\n",
      "[]\n",
      "[{'entity': 'B-PER', 'score': 0.99826485, 'index': 4, 'word': 'juhani', 'start': 12, 'end': 18}, {'entity': 'I-PER', 'score': 0.9983398, 'index': 5, 'word': 'numminen', 'start': 19, 'end': 27}, {'entity': 'B-LOC', 'score': 0.9736143, 'index': 8, 'word': 'espoossa', 'start': 36, 'end': 44}]\n",
      "[{'entity': 'B-PER', 'score': 0.9960212, 'index': 4, 'word': 'juhani', 'start': 12, 'end': 18}, {'entity': 'I-PER', 'score': 0.99781346, 'index': 5, 'word': 'teppo', 'start': 19, 'end': 24}, {'entity': 'I-PER', 'score': 0.99778867, 'index': 6, 'word': 'numminen', 'start': 25, 'end': 33}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62debf70ab584793af8a2d9878312263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-LOC', 'score': 0.96721745, 'index': 4, 'word': 'helsingin', 'start': 14, 'end': 23}, {'entity': 'B-LOC', 'score': 0.47763294, 'index': 5, 'word': '##tie', 'start': 23, 'end': 26}, {'entity': 'I-LOC', 'score': 0.633142, 'index': 6, 'word': '10', 'start': 27, 'end': 29}, {'entity': 'B-PER', 'score': 0.9971386, 'index': 12, 'word': 'esko', 'start': 46, 'end': 50}, {'entity': 'I-PER', 'score': 0.98933697, 'index': 13, 'word': 'esimerkki', 'start': 51, 'end': 60}]\n",
      "[{'entity': 'B-LOC', 'score': 0.8599525, 'index': 2, 'word': 'helsingissa', 'start': 5, 'end': 16}, {'entity': 'B-PER', 'score': 0.99738044, 'index': 6, 'word': 'asko', 'start': 28, 'end': 32}, {'entity': 'I-PER', 'score': 0.99898237, 'index': 7, 'word': 'arvo', 'start': 33, 'end': 37}, {'entity': 'I-PER', 'score': 0.9988759, 'index': 8, 'word': '##la', 'start': 37, 'end': 39}]\n",
      "[]\n",
      "[{'entity': 'B-PER', 'score': 0.99826485, 'index': 4, 'word': 'juhani', 'start': 12, 'end': 18}, {'entity': 'I-PER', 'score': 0.9983398, 'index': 5, 'word': 'numminen', 'start': 19, 'end': 27}, {'entity': 'B-LOC', 'score': 0.9736143, 'index': 8, 'word': 'espoossa', 'start': 36, 'end': 44}]\n",
      "[{'entity': 'B-PER', 'score': 0.9960212, 'index': 4, 'word': 'juhani', 'start': 12, 'end': 18}, {'entity': 'I-PER', 'score': 0.99781346, 'index': 5, 'word': 'teppo', 'start': 19, 'end': 24}, {'entity': 'I-PER', 'score': 0.99778867, 'index': 6, 'word': 'numminen', 'start': 25, 'end': 33}]\n",
      "194 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1\n",
    "#ALTERNATIVE VERSION\n",
    "#This is a basic version that prints out results into notebook\n",
    "for out in tqdm(pipeline(KeyDataset(dataset, \"Text\"))):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8599e32-8692-4307-8fc8-5b6e7d248477",
   "metadata": {},
   "source": [
    "## Run dataset through the Llama 2 chat engine and check recognized entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4aa9f449-05a8-4496-aa82-950c4db3a642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\"><caption>Selected Rows from Table TEST_ANONYMIZATION_LLM</caption>\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th title=\"\"></th>\n",
       "      <th title=\"ID\">ID</th>\n",
       "      <th title=\"Text\">Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Extract the entities and their start positions in the following sentence: 'Osoitteeni on Helsingintie 10 A 15. Nimeni on Esko Esimerkki.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Extract the entities and their start positions in the following sentence: 'Asun Helsingissä. Nimeni on Asko Arvola.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Extract the entities and their start positions in the following sentence: 'Puhelinnumeroni on 040 123 899 3454.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Extract the entities and their start positions in the following sentence: 'Mun nimi on Juhani Numminen ja asun Espoossa.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Extract the entities and their start positions in the following sentence: 'Mun nimi on Juhani Teppo Numminen.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Selected Rows from Table TEST_ANONYMIZATION_LLM\n",
       "\n",
       "    ID                                                                                                                                       Text\n",
       "0  1.0  Extract the entities and their start positions in the following sentence: 'Osoitteeni on Helsingintie 10 A 15. Nimeni on Esko Esimerkki.'\n",
       "1  2.0                       Extract the entities and their start positions in the following sentence: 'Asun Helsingissä. Nimeni on Asko Arvola.'\n",
       "2  3.0                           Extract the entities and their start positions in the following sentence: 'Puhelinnumeroni on 040 123 899 3454.'\n",
       "3  4.0                  Extract the entities and their start positions in the following sentence: 'Mun nimi on Juhani Numminen ja asun Espoossa.'\n",
       "4  5.0                             Extract the entities and their start positions in the following sentence: 'Mun nimi on Juhani Teppo Numminen.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Query for the LLM needs to be in the data table (as in this case) or concatenated in the for-loop\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "tbl_2 = conn.CASTable('TEST_ANONYMIZATION_LLM', caslib='CASUSER')\n",
    "df_2 = tbl_2.to_frame().head()\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c288618-6f6d-437b-9786-abd2f98c5fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                        Result\n",
      "0   Sure! Here are the entities and their start positions in the sentence you provided:\\n\\nEntities:\\n\\n1. Osoitteeni (Address) - Start position: 0\\n2. Nimeni (My name) - Start position: 9\\n3. Esko (Esko) - Start position: 14\\n4. Esimerkki (Example) - Start position: 19\\n\\nI hope this helps! Let me...\n",
      "1   Sure! Here are the entities and their start positions in the sentence you provided:\\n\\nEntities:\\n\\n1. Asun (I live in) - Start position: 0\\n2. Nimeni (My name) - Start position: 9\\n3. Asko (Asko) - Start position: 14\\n4. Arvola (Arvola) - Start position: 19\\n\\nI hope this helps! Let me know if...\n",
      "2   Sure! Here are the entities and their start positions in the sentence you provided:\\n\\nEntities:\\n\\n1. Puhelinnumeroni (Phone number) - Start position: 0\\n2. 040 (Area code) - Start position: 5\\n3. 123 (Area code) - Start position: 9\\n4. 899 (Area code) - Start position: 14\\n5. 3454 (Phone numb...\n",
      "3   Sure! Here are the entities and their start positions in the sentence you provided:\\n\\nEntities:\\n\\n1. Mun (My) - Start position: 0\\n2. nimi (Name) - Start position: 5\\n3. Juhani (Juhani) - Start position: 9\\n4. Numminen (Juhani Numminen) - Start position: 14\\n5. asun (I live in) - Start positi...\n",
      "4   Sure! Here are the entities and their start positions in the sentence you provided:\\n\\nEntities:\\n\\n1. Mun (My) - Start position: 0\\n2. nimi (Name) - Start position: 5\\n3. Juhani (Juhani) - Start position: 9\\n4. Teppo (Teppo) - Start position: 14\\n5. Numminen (Numminen) - Start position: 19\\n\\n...\n"
     ]
    }
   ],
   "source": [
    "#%%timeit -r 1\n",
    "#Runtime is 10+ min\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "#Define empty frame\n",
    "outputtbl_2 = []\n",
    "\n",
    "#Define for-loop\n",
    "#Text variable in the dataset object is fed into the Llama 2 chat engine defined earlier\n",
    "counter_2 = 0\n",
    "for out_2 in range(df_2.shape[0]):\n",
    "    result_2 = {\n",
    "        'Result': chat_engine.chat(df_2.iloc[counter_2,1]).response\n",
    "    }\n",
    "    outputtbl_2.append(result_2)\n",
    "    counter_2 += 1\n",
    "\n",
    "#Results are available in the dataframe\n",
    "outdf_2 = pd.DataFrame(outputtbl_2)\n",
    "print(outdf_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12497ecf-2e5d-4184-83f4-fb7a559514d8",
   "metadata": {},
   "source": [
    "## Upload dataframe to SAS Viya in-memory table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54f86b50-2851-4d99-b1d9-68c9a04151b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the uploaded file available as table OUTPUTTBLCAS in caslib CASUSER(ssfahe).\n",
      "NOTE: The table OUTPUTTBLCAS has been created in caslib CASUSER(ssfahe) from binary data uploaded to Cloud Analytic Services.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; caslib</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>CASUSER(ssfahe)</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; tableName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>OUTPUTTBLCAS</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; casTable</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>CASTable('OUTPUTTBLCAS', caslib='CASUSER(ssfahe)')</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.00569s</span> &#183; <span class=\"cas-user\">user 0.00147s</span> &#183; <span class=\"cas-sys\">sys 0.0062s</span> &#183; <span class=\"cas-memory\">mem 41.3MB</span></small></p>"
      ],
      "text/plain": [
       "[caslib]\n",
       "\n",
       " 'CASUSER(ssfahe)'\n",
       "\n",
       "[tableName]\n",
       "\n",
       " 'OUTPUTTBLCAS'\n",
       "\n",
       "[casTable]\n",
       "\n",
       " CASTable('OUTPUTTBLCAS', caslib='CASUSER(ssfahe)')\n",
       "\n",
       "+ Elapsed: 0.00569s, user: 0.00147s, sys: 0.0062s, mem: 41.3mb"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://github.com/sassoftware/sas-viya-the-python-perspective/blob/main/Chapter%204%20-%20Managing%20Your%20Data%20in%20CAS.ipynb\n",
    "#Upload the outdf dataframe back into SAS Viya as an in-memory table\n",
    "conn.upload(outdf, casout=dict(name='outputtblcas', caslib='casuser', promote='yes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b6510-9929-4b7f-8bea-579ced3c7ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
